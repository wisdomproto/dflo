"""
PDF â†’ RAG ì‹œìŠ¤í…œ (100% ë¬´ë£Œ ë²„ì „)
- Google Geminië¡œ ì„ë² ë”© + ë‹µë³€ ìƒì„±
- ë¡œì»¬ ë²¡í„° DB (Chroma) ì‚¬ìš©
- OpenAI/Pinecone ë¶ˆí•„ìš”!
"""

import os
import json
import PyPDF2
import re
from pathlib import Path
from typing import List, Dict
import google.generativeai as genai
import chromadb
from chromadb.utils import embedding_functions
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
genai.configure(api_key=GEMINI_API_KEY)

class PDFtoRAGFree:
    def __init__(self, pdf_path: str, collection_name: str = "growth_bible"):
        self.pdf_path = pdf_path
        self.collection_name = collection_name
        self.chunks = []
        
        # Chroma DB ì´ˆê¸°í™” (ë¡œì»¬ ì €ì¥)
        self.chroma_client = chromadb.PersistentClient(path="./chroma_db")
        
        # Gemini ì„ë² ë”© í•¨ìˆ˜
        self.embedding_function = embedding_functions.GoogleGenerativeAiEmbeddingFunction(
            api_key=GEMINI_API_KEY
        )
        
        # ì»¬ë ‰ì…˜ ìƒì„± ë˜ëŠ” ê°€ì ¸ì˜¤ê¸°
        try:
            self.collection = self.chroma_client.get_collection(
                name=collection_name,
                embedding_function=self.embedding_function
            )
            print(f"âœ… ê¸°ì¡´ ì»¬ë ‰ì…˜ ë¡œë“œ: {collection_name}")
        except:
            self.collection = self.chroma_client.create_collection(
                name=collection_name,
                embedding_function=self.embedding_function,
                metadata={"description": "ì„±ì¥ ë°”ì´ë¸” RAG ì‹œìŠ¤í…œ"}
            )
            print(f"âœ… ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {collection_name}")
    
    def extract_text_from_pdf(self) -> str:
        """PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        print(f"\nğŸ“„ PDF íŒŒì¼ ì½ëŠ” ì¤‘: {self.pdf_path}")
        
        text = ""
        try:
            with open(self.pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                total_pages = len(pdf_reader.pages)
                
                for page_num, page in enumerate(pdf_reader.pages, 1):
                    page_text = page.extract_text()
                    text += f"\n\n[í˜ì´ì§€ {page_num}]\n{page_text}"
                    
                    if page_num % 10 == 0:
                        print(f"   ì§„í–‰ë¥ : {page_num}/{total_pages} í˜ì´ì§€")
            
            print(f"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: ì´ {len(text):,}ì")
            return text
        except Exception as e:
            print(f"âŒ PDF ì½ê¸° ì˜¤ë¥˜: {e}")
            raise
    
    def clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì •ë¦¬"""
        # ê³¼ë„í•œ ì¤„ë°”ê¿ˆ ì œê±°
        text = re.sub(r'\n{3,}', '\n\n', text)
        # ê³µë°± ì •ë¦¬
        text = re.sub(r' +', ' ', text)
        return text.strip()
    
    def split_into_chunks(self, text: str, chunk_size: int = 1000, overlap: int = 200) -> List[Dict]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• """
        print(f"\nğŸ“‹ í…ìŠ¤íŠ¸ ì²­í¬ ë¶„í•  ì¤‘ (í¬ê¸°: {chunk_size}, ì˜¤ë²„ë©: {overlap})")
        
        # í˜ì´ì§€ë³„ë¡œ ë¨¼ì € ë¶„í• 
        pages = text.split('[í˜ì´ì§€')
        chunks = []
        
        for page_text in pages:
            if not page_text.strip():
                continue
            
            # í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ
            page_match = re.match(r'(\d+)\]', page_text)
            page_num = int(page_match.group(1)) if page_match else 0
            
            # ì„¹ì…˜ë³„ë¡œ ë¶„í• 
            sections = re.split(r'(##\s+[^\n]+)', page_text)
            
            current_section_title = "ë„ì…ë¶€"
            current_text = ""
            
            for section in sections:
                if section.startswith('##'):
                    # ì´ì „ ì„¹ì…˜ ì €ì¥
                    if current_text.strip():
                        self._create_chunks_from_text(
                            current_text, 
                            current_section_title, 
                            page_num, 
                            chunks, 
                            chunk_size, 
                            overlap
                        )
                    
                    # ìƒˆ ì„¹ì…˜ ì‹œì‘
                    current_section_title = section.strip()
                    current_text = ""
                else:
                    current_text += section
            
            # ë§ˆì§€ë§‰ ì„¹ì…˜ ì €ì¥
            if current_text.strip():
                self._create_chunks_from_text(
                    current_text, 
                    current_section_title, 
                    page_num, 
                    chunks, 
                    chunk_size, 
                    overlap
                )
        
        print(f"âœ… ì´ {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
        self.chunks = chunks
        return chunks
    
    def _create_chunks_from_text(self, text: str, title: str, page_num: int, 
                                   chunks: List[Dict], chunk_size: int, overlap: int):
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€"""
        text = self.clean_text(text)
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
        sentences = re.split(r'([.!?]\s+)', text)
        
        current_chunk = ""
        chunk_count = 0
        
        for i in range(0, len(sentences), 2):
            sentence = sentences[i] + (sentences[i+1] if i+1 < len(sentences) else '')
            
            if len(current_chunk) + len(sentence) > chunk_size:
                if current_chunk:
                    chunks.append({
                        'id': f'chunk_{len(chunks):05d}',
                        'text': current_chunk.strip(),
                        'metadata': {
                            'title': title,
                            'page': str(page_num),
                            'chunk_index': str(chunk_count),
                            'source': 'growth_bible_pdf'
                        }
                    })
                    chunk_count += 1
                    current_chunk = current_chunk[-overlap:] if len(current_chunk) > overlap else ""
            
            current_chunk += sentence
        
        # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
        if current_chunk.strip():
            chunks.append({
                'id': f'chunk_{len(chunks):05d}',
                'text': current_chunk.strip(),
                'metadata': {
                    'title': title,
                    'page': str(page_num),
                    'chunk_index': str(chunk_count),
                    'source': 'growth_bible_pdf'
                }
            })
    
    def upload_to_chroma(self):
        """Chroma DBì— ì²­í¬ ì—…ë¡œë“œ"""
        print(f"\nğŸ”„ Chroma DBì— ì—…ë¡œë“œ ì¤‘...")
        
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸
        existing_count = self.collection.count()
        if existing_count > 0:
            print(f"âš ï¸  ê¸°ì¡´ ë°ì´í„° {existing_count}ê°œ ë°œê²¬. ì‚­ì œ í›„ ì¬ì—…ë¡œë“œí•©ë‹ˆë‹¤.")
            # ì»¬ë ‰ì…˜ ì‚­ì œ í›„ ì¬ìƒì„±
            self.chroma_client.delete_collection(self.collection_name)
            self.collection = self.chroma_client.create_collection(
                name=self.collection_name,
                embedding_function=self.embedding_function,
                metadata={"description": "ì„±ì¥ ë°”ì´ë¸” RAG ì‹œìŠ¤í…œ"}
            )
        
        # ë°°ì¹˜ë¡œ ì—…ë¡œë“œ
        batch_size = 100
        total_chunks = len(self.chunks)
        
        for i in range(0, total_chunks, batch_size):
            batch = self.chunks[i:i+batch_size]
            
            ids = [chunk['id'] for chunk in batch]
            documents = [chunk['text'] for chunk in batch]
            metadatas = [chunk['metadata'] for chunk in batch]
            
            try:
                self.collection.add(
                    ids=ids,
                    documents=documents,
                    metadatas=metadatas
                )
                print(f"   ì—…ë¡œë“œ ì§„í–‰: {min(i+batch_size, total_chunks)}/{total_chunks} ({min(i+batch_size, total_chunks)/total_chunks*100:.1f}%)")
            except Exception as e:
                print(f"âš ï¸  ë°°ì¹˜ {i//batch_size + 1} ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"âœ… ì—…ë¡œë“œ ì™„ë£Œ! ì´ {self.collection.count()}ê°œ ë¬¸ì„œ")
    
    def search(self, query: str, top_k: int = 5) -> List[Dict]:
        """ì¿¼ë¦¬ë¡œ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰"""
        results = self.collection.query(
            query_texts=[query],
            n_results=top_k,
            include=['documents', 'metadatas', 'distances']
        )
        
        # ê²°ê³¼ í¬ë§·íŒ…
        docs = []
        for i in range(len(results['ids'][0])):
            docs.append({
                'id': results['ids'][0][i],
                'text': results['documents'][0][i],
                'metadata': results['metadatas'][0][i],
                'distance': results['distances'][0][i],
                'score': 1 - results['distances'][0][i]  # ìœ ì‚¬ë„ë¡œ ë³€í™˜
            })
        
        return docs
    
    def run(self):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        print("=" * 60)
        print("ğŸš€ PDF â†’ RAG ìë™ êµ¬ì¶• ì‹œì‘! (100% ë¬´ë£Œ)")
        print("=" * 60)
        
        # 1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = self.extract_text_from_pdf()
        
        # 2. ì²­í¬ ë¶„í• 
        chunks = self.split_into_chunks(text, chunk_size=1000, overlap=200)
        
        # 3. Chroma DB ì—…ë¡œë“œ
        self.upload_to_chroma()
        
        print("\n" + "=" * 60)
        print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        print("=" * 60)
        print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
        print(f"   - ì´ ì²­í¬ ìˆ˜: {len(self.chunks):,}")
        print(f"   - Chroma DB ì €ì¥ ìœ„ì¹˜: ./chroma_db/")
        print(f"   - ì»¬ë ‰ì…˜ ì´ë¦„: {self.collection_name}")
        print(f"\nğŸ’° ë¹„ìš©: $0 (ì™„ì „ ë¬´ë£Œ!)")
        print(f"\nğŸ‰ ì´ì œ AI ì±—ë´‡ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")


def test_search(collection_name: str = "growth_bible"):
    """ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("ğŸ§ª ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # Chroma í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    chroma_client = chromadb.PersistentClient(path="./chroma_db")
    embedding_function = embedding_functions.GoogleGenerativeAiEmbeddingFunction(
        api_key=GEMINI_API_KEY
    )
    
    collection = chroma_client.get_collection(
        name=collection_name,
        embedding_function=embedding_function
    )
    
    # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
    test_queries = [
        "ì•„ì´ê°€ ë°¥ì„ ì•ˆ ë¨¹ëŠ”ë° ì–´ë–»ê²Œ í•´ì•¼ í•˜ë‚˜ìš”?",
        "ì„±ì¥í˜¸ë¥´ëª¬ ì£¼ì‚¬ëŠ” ì–¸ì œë¶€í„° ë§ì•„ì•¼ í•˜ë‚˜ìš”?",
        "í‚¤ê°€ ì‘ì€ ì•„ì´ë¥¼ ìœ„í•œ ìš´ë™ì€ ë­ê°€ ì¢‹ë‚˜ìš”?"
    ]
    
    for query in test_queries:
        print(f"\nâ“ ì§ˆë¬¸: {query}")
        print("-" * 60)
        
        results = collection.query(
            query_texts=[query],
            n_results=3
        )
        
        for i in range(len(results['ids'][0])):
            meta = results['metadatas'][0][i]
            doc = results['documents'][0][i]
            dist = results['distances'][0][i]
            score = 1 - dist
            
            print(f"\nğŸ“„ ê²°ê³¼ {i+1} (ìœ ì‚¬ë„: {score:.2%})")
            print(f"   ì œëª©: {meta.get('title', 'N/A')}")
            print(f"   í˜ì´ì§€: {meta.get('page', 'N/A')}")
            print(f"   ë‚´ìš©: {doc[:200]}...")


if __name__ == "__main__":
    import sys
    
    # ëª…ë ¹ì¤„ ì¸ìˆ˜ë¡œ PDF ê²½ë¡œì™€ ì»¬ë ‰ì…˜ ì´ë¦„ ë°›ê¸°
    if len(sys.argv) >= 2:
        pdf_path = sys.argv[1]
        collection_name = sys.argv[2] if len(sys.argv) >= 3 else "growth_bible"
    else:
        pdf_path = "ìš°ë¦¬ ì•„ì´ í‚¤ ì„±ì¥ ë°”ì´ë¸” ì›ê³ .pdf"
        collection_name = "growth_bible"
    
    print(f"ğŸ“„ PDF íŒŒì¼: {pdf_path}")
    print(f"ğŸ“¦ ì»¬ë ‰ì…˜: {collection_name}")
    print("")
    
    if not os.path.exists(pdf_path):
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        print(f"   í˜„ì¬ ë””ë ‰í† ë¦¬: {os.getcwd()}")
        print("")
        print("ì‚¬ìš©ë²•:")
        print(f"  python {sys.argv[0]} <PDFê²½ë¡œ> [ì»¬ë ‰ì…˜ëª…]")
        print("")
        print("ì˜ˆì‹œ:")
        print(f"  python {sys.argv[0]} ../ìš°ë¦¬ì•„ì´í‚¤ì„±ì¥ë°”ì´ë¸”ì›ê³ .pdf growth_bible")
        sys.exit(1)
    
    # RAG ì‹œìŠ¤í…œ êµ¬ì¶•
    rag_builder = PDFtoRAGFree(pdf_path, collection_name=collection_name)
    rag_builder.run()
    
    # ìë™ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (Enter ëŒ€ê¸° ì œê±°)
    print("\nğŸ§ª ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
    try:
        test_search(collection_name)
    except Exception as e:
        print(f"âš ï¸  í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ (ë¬´ì‹œ ê°€ëŠ¥): {e}")
    
    print("\n" + "=" * 60)
    print("âœ… ì„¤ì • ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„:")
    print("1. ë¡œì»¬ API ì„œë²„ ì‹¤í–‰: uvicorn local_api_server:app --port 5000")
    print("2. ì›¹ì•± ì‹¤í–‰ (ìƒˆ í„°ë¯¸ë„): python -m http.server 8000")
    print("3. ë¸Œë¼ìš°ì €: http://localhost:8000/info.html")
    print("=" * 60)
